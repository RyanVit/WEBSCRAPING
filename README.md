# Web Scraping Mercado Livre - Case Samsung


## ğŸ“– DescriÃ§Ã£o do Projeto

Este projeto implementa um pipeline de ETL (ExtraÃ§Ã£o, TransformaÃ§Ã£o e Carregamento) para dados de notebooks disponÃ­veis no Mercado Livre. Utiliza o framework Scrapy para coleta de dados, pandas para manipulaÃ§Ã£o e transformaÃ§Ã£o, e Streamlit para visualizaÃ§Ã£o interativa. O objetivo Ã© construir uma base de dados estruturada para anÃ¡lise de mercado.

---

## ğŸ› ï¸ Estrutura do RepositÃ³rio

```plaintext
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ data.jsonl          # Dados brutos extraÃ­dos
â”‚   â”œâ”€â”€ mercadolivre.db     # Banco de dados SQLite com dados processados
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ dashboard/
â”‚   â”‚   â””â”€â”€ app.py          # Interface interativa com Streamlit
â”‚   â”œâ”€â”€ extraction/
â”‚   â”‚   â”œâ”€â”€ scrapy.cfg      # ConfiguraÃ§Ã£o do Scrapy
â”‚   â”‚   â””â”€â”€ coleta/
â”‚   â”‚       â”œâ”€â”€ spiders/
â”‚   â”‚       â”‚   â””â”€â”€ notebook.py  # Spider para scraping de notebooks
â”‚   â”‚       â”œâ”€â”€ items.py    # DefiniÃ§Ã£o de modelos de dados do Scrapy
â”‚   â”‚       â”œâ”€â”€ settings.py # ConfiguraÃ§Ãµes do Scrapy
â”‚   â”œâ”€â”€ transformLoad/
â”‚       â””â”€â”€ main.py         # Script para transformaÃ§Ã£o e carregamento
```

---

## ğŸš€ Funcionalidades Principais

1. **ExtraÃ§Ã£o de Dados**:
   - O spider [`NotebookSpider`](src/extraction/coleta/spiders/notebook.py) coleta informaÃ§Ãµes como marca, modelo, preÃ§o, avaliaÃ§Ãµes e vendedor diretamente do Mercado Livre.

2. **TransformaÃ§Ã£o de Dados**:
   - O script [`main.py`](src/transformLoad/main.py) realiza:
     - Tratamento de valores ausentes.
     - ConversÃ£o de tipos para colunas numÃ©ricas.
     - Filtragem de produtos com base em critÃ©rios especÃ­ficos.

3. **Carregamento de Dados**:
   - Os dados processados sÃ£o armazenados em um banco de dados SQLite ([`mercadolivre.db`](data/mercadolivre.db)).

4. **VisualizaÃ§Ã£o Interativa**:
   - O dashboard Streamlit ([`app.py`](src/dashboard/app.py)) apresenta os dados com KPIs e grÃ¡ficos dinÃ¢micos.

---

## ğŸ› ï¸ Tecnologias e Ferramentas

- **Python**: Linguagem principal para desenvolvimento.
- **Scrapy**: Framework para web scraping.
- **Pandas**: Biblioteca para manipulaÃ§Ã£o e anÃ¡lise de dados.
- **SQLite**: Banco de dados relacional leve.
- **Streamlit**: Ferramenta para criaÃ§Ã£o de dashboards interativos.

---

## ğŸ“¦ Guia de InstalaÃ§Ã£o

1. **Clone o repositÃ³rio**:
   ```bash
   
   ```

2. **Instale as dependÃªncias**:
   ```bash
   pip install -r requirements.txt
   ```

3. **Execute o spider para coleta de dados**:
   ```bash
   scrapy crawl notebook
   ```

4. **Realize a transformaÃ§Ã£o e carregamento dos dados**:
   ```bash
   python src/transformLoad/main.py
   ```

5. **Inicie o dashboard interativo**:
   ```bash
   streamlit run src/dashboard/app.py
   ```

---

## ğŸ“Š VisualizaÃ§Ã£o e AnÃ¡lise

O dashboard interativo apresenta:

- **Indicadores-Chave (KPIs)**:
  - Total de itens coletados.
  - PreÃ§o mÃ©dio dos notebooks.
  - AvaliaÃ§Ã£o mÃ©dia dos produtos.
  - Marca que se destacou

- **GrÃ¡ficos e Tabelas**:
  - DistribuiÃ§Ã£o de preÃ§os.
  - AvaliaÃ§Ãµes por marca.

---

## ğŸ“ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Para contribuir:

1. FaÃ§a um fork do repositÃ³rio.
2. Crie uma branch para sua feature:
   ```bash
   git checkout -b minha-feature
   ```
3. Realize os commits das alteraÃ§Ãµes:
   ```bash
   git commit -m "ImplementaÃ§Ã£o da minha feature"
   ```
4. Envie para o repositÃ³rio remoto:
   ```bash
   git push origin minha-feature
   ```
5. Abra um Pull Request para revisÃ£o.

---

## ğŸ›¡ï¸ Licenciamento

Este projeto estÃ¡ licenciado sob a [LicenÃ§a MIT](LICENSE).

---

## ğŸ™Œ Agradecimentos

Este projeto foi desenvolvido como parte da iniciativa **Jornada de Dados**. Para mais informaÃ§Ãµes, acesse [Jornada de Dados](https://suajornadadedados.com.br/).
